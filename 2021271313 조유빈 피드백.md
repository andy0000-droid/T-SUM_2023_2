# 2021271313 조유빈 피드백
## 1세대 딥러닝
xor 문제에 대한 설명 추가    
선형 분류에 대한 설명 추가
## 활성화 함수
softmax 함수 각 클래스 별 확률을 출력해준다는 설명 추가
## 손실 함수
식에 대한 건 굳이 알 필요 없음    
손실 함수의 종류와 각각의 특징 정도만 알아두면 충분    
보통은 손실 함수를 구현해둔 모듈을 사용    
## 딥러닝의 최적화 기법
바이어스랑 가중치의 차이: 쉽게 말하자면 가중치는 계수, 바이어스는 상수    
가중치를 조절하게 되면 그래프의 전체적인 모양이 변경됨    
바이어스를 조절하게 되면 그래프의 y축 이동만 변경됨
### 모멘텀
기울기의 최소값이 아닌 극값에서 학습을 종료하는 것을 방지함과 같은 설명 추가    
알고리즘 4개 다 식까지 알아야되는지 -> 알 필요 없음
## 규제 기법
과대 적합에 대한 설명 추가
### 가중치 감소
놈과 람다에 대한 건 알 필요 없지만 가중치 감소가 일반적인 손실 함수와 어떤 부분이 다른 지는 알아두길 바람
### 데이터 증대
이미지 데이터인 경우에 데이터 증대에 사용할 수 있는 방법들이므로 예시도 알아두길 바람
### Dropout
각 epoch마다 서로 다른 네트워크로 학습하는 효과도 기대할 수 있음과 같은 설명 추가
